â˜• Coffee Sales Exploratory Data Analysis
## 1. Abstract

This project focuses on performing **Exploratory Data Analysis (EDA)** on a coffee sales dataset using Python. The primary goal is to uncover insights into sales patterns, customer behavior, and product performance. The analysis involves data inspection, cleaning, preprocessing, and visualization to understand key metrics such as sales distribution across different times of the day, months, and years, as well as the popularity and revenue generated by various coffee types. The project also demonstrates the generation and integration of synthetic data to enhance the dataset for a more comprehensive analysis [2, 3].

## 2. Introduction

Exploratory Data Analysis (EDA) is a crucial step in any data science project, allowing us to understand the underlying structure of the data, identify important variables, detect anomalies, and test assumptions. This project applies EDA techniques to a coffee sales dataset to extract meaningful information that can inform business decisions. The relevance of this project lies in providing actionable insights into sales trends, which can help in inventory management, marketing strategies, and optimizing operational hours [4, 5].

The project leverages **Python** as the primary programming language, utilizing powerful libraries such as **pandas** for data manipulation, **numpy** for numerical operations, and **matplotlib.pyplot** and **seaborn** for data visualization [1]. The dataset includes detailed information on individual coffee transactions, such as `hour_of_day`, `cash_type`, `money` (sales amount), `coffee_name`, `Time_of_Day`, `Weekday`, `Month_name`, `Date`, and `Time` [1, 6].

## 3. Project Objectives

The main objectives of this coffee sales EDA project are:

*   **To perform initial data inspection** to ascertain the number of columns, identify duplicate columns, and detect any missing values in the dataset [7, 8].
*   **To understand the basic statistical properties and data types** of each column in the original and combined datasets [9, 10].
*   **To analyze sales trends over time**, including average money made per year and maximum money generated per month [9, 11-14].
*   **To identify popular coffee types** and understand the distribution of money generated by different coffee names [15-18].
*   **To investigate sales patterns based on the time of day**, determining the average money made during Morning, Afternoon, and Night shifts [19-21].
*   **To demonstrate synthetic data generation** to augment the original dataset and perform subsequent analysis on the combined data [2, 3].

## 4. Methodology

The project followed a structured methodology for data analysis:

1.  **Data Collection and Loading**: The coffee sales data was loaded from a CSV file named `Coffe_sales.csv` into a pandas DataFrame [1].
2.  **Initial Data Inspection**:
    *   The **number of columns** in the original dataset was determined to be 11 [7].
    *   **Duplicate columns** were checked, and none were found [7].
    *   **Missing values** were assessed, and the original dataset was found to have no missing values [7].
3.  **Data Preprocessing**:
    *   The `Date` column, initially an `object` datatype, was converted to `datetime` objects to facilitate time-based analysis [9].
    *   New columns, `Month` and `Year`, were extracted from the `Date` column [9, 10].
    *   To ensure accuracy in time-based analysis, rows with null values in the `Year` column (potentially arising from date coercion) were dropped, and the `Year` column was converted to `int` [10, 12].
4.  **Synthetic Data Generation**:
    *   **100 rows of synthetic data** were generated to augment the existing dataset [2].
    *   For `object` type columns, values were randomly sampled from the unique values of the original column.
    *   For `numerical` (int64, float64) type columns, random numbers were generated within the minimum and maximum range of the original column.
    *   For `datetime` columns, random dates were generated within the range of existing dates [2].
5.  **Data Combination**: The original `coffee_data` and the `synthetic_data` were concatenated to create a `combined_coffee_data` DataFrame, which had 3647 rows and 13 columns [3].
6.  **Combined Data Re-inspection**:
    *   The combined dataset was re-inspected, revealing 13 columns and 0 duplicate columns [8, 20].
    *   It was noted that the `Month` column in the combined data had 100 missing values, likely due to how synthetic data was generated or combined [22].
    *   Basic statistics were reviewed for the combined dataset [10].
7.  **Data Analysis**:
    *   Calculated the **average money by year** for the combined data, showing values for 2024 and 2025 [12, 14].
    *   Determined the **maximum money by month** in the combined dataset, showing varying peak sales across months [13, 14].
    *   Identified the **number of unique coffee types** (8 types) in the combined dataset [17, 18].
    *   Found the **maximum money from each coffee name** in the combined data [17, 18].
    *   Calculated the **average money made at different times of the day** (Morning, Afternoon, Night) in the combined data [20, 21].
8.  **Data Visualization**:
    *   **Line plot** illustrating the distribution of money over months [23].
    *   **Bar plot** showing the density of money over years [16].
    *   **Box plot** depicting the distribution of money across different coffee names [16].
    These visualizations were generated using `matplotlib.pyplot` and `seaborn` [11, 16, 23].

## 5. Data Analysis and Results

The analysis of the coffee sales data revealed several key findings:

*   **Dataset Dimensions**: The original dataset comprised 3547 entries across 11 columns [1, 7]. After preprocessing and combining with 100 rows of synthetic data, the `combined_coffee_data` contained 3647 entries and 13 columns [3, 8].
*   **Data Quality**: The original data was clean with no missing or duplicate columns [7]. In the combined dataset, 100 missing values were observed in the `Month` column, which might need further handling depending on the specific analysis [22].
*   **Coffee Variety**: There are **8 distinct types of coffees** available in the dataset [15, 17, 18].
*   **Peak Sales by Coffee Type**: In both original and combined data, **Cappuccino, Cocoa, Hot Chocolate, and Latte consistently showed the highest maximum sales values (38.7)** [15, 18]. Other coffee types like Cortado, Espresso, and Americano also reached high maximum sales in the combined dataset [18].
*   **Time of Day Sales Performance**: Sales revenue varied by time of day, with **Night (average ~32.78) generally generating the highest average money, followed by Afternoon (average ~31.59), and then Morning (average ~30.29)** in the combined data [19-21]. This suggests higher customer spending or volume during later hours.
*   **Yearly Sales Trends**: The **average money by year** in the combined data showed slight variations, with **2024 having an average of ~31.62 and 2025 having ~31.31** [14].
*   **Monthly Sales Variation**: Maximum sales values varied significantly across months, with **March and April showing the highest peaks** (38.70) in both original and combined data [11, 14]. Other months like May, June, July, September, and October also showed strong maximum sales [14].
*   **Visualizations**: Graphical representations confirmed these trends, providing clear insights into the distribution of money over months, years, and coffee names [11, 16, 23].

## 6. Conclusion

This Exploratory Data Analysis project successfully provided valuable insights into the coffee sales data. We identified key characteristics of the dataset, performed necessary data preprocessing, and analyzed sales performance across various dimensions such as time of day, month, year, and coffee type. The analysis highlights that **certain coffee types (Cappuccino, Cocoa, Hot Chocolate, Latte) frequently achieve the highest individual sales values**, and **sales tend to be higher during the Night and Afternoon periods** [15, 18, 19, 21]. Monthly sales patterns indicate peak performance around March and April [11, 14]. The generation and integration of synthetic data allowed for a broader analysis and demonstrated a method for augmenting datasets.

**Recommendations for Future Work**:
*   **Predictive Modeling**: Develop machine learning models to forecast future sales based on historical data and identified trends [24].
*   **Customer Segmentation**: Analyze purchase patterns to segment customers and tailor marketing strategies.
